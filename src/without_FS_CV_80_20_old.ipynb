{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4304ddd-7ba5-4128-8b9b-28cf8a41c13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Validation Accuracy: 97.50%\n",
      "Fold 2 Validation Accuracy: 97.19%\n",
      "Fold 3 Validation Accuracy: 97.58%\n",
      "Fold 4 Validation Accuracy: 97.50%\n",
      "Fold 5 Validation Accuracy: 97.50%\n",
      "Fold 6 Validation Accuracy: 97.34%\n",
      "Fold 7 Validation Accuracy: 97.47%\n",
      "Fold 8 Validation Accuracy: 97.63%\n",
      "Fold 9 Validation Accuracy: 97.55%\n",
      "Fold 10 Validation Accuracy: 97.97%\n",
      "\n",
      "Average Cross-Validation Accuracy: 97.52%\n",
      "\n",
      "Test Set Accuracy: 97.40%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4632  175]\n",
      " [  75 4720]]\n"
     ]
    }
   ],
   "source": [
    "########## RF ########\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Merge_all_features_1639_with_class.csv')\n",
    "\n",
    "# Split into features and target variable\n",
    "X = df.drop(columns=df.columns[-1])\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "# Split data into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up KFold cross-validation with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "fold = 1\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_fold_train, y_fold_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    clf_rf.fit(X_fold_train, y_fold_train)\n",
    "    y_fold_pred = clf_rf.predict(X_fold_val)\n",
    "    fold_accuracy = accuracy_score(y_fold_val, y_fold_pred)\n",
    "    cv_scores.append(fold_accuracy)\n",
    "    \n",
    "    print(f\"Fold {fold} Validation Accuracy: {fold_accuracy*100:.2f}%\")\n",
    "    fold += 1\n",
    "\n",
    "# Calculate the mean cross-validation accuracy\n",
    "mean_cv_accuracy = sum(cv_scores) / len(cv_scores)\n",
    "print(f\"\\nAverage Cross-Validation Accuracy: {mean_cv_accuracy*100:.2f}%\")\n",
    "\n",
    "# Train the model on the entire training set\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "\n",
    "# Calculate the test set accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"\\nTest Set Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Generate and print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49dde8-2885-4a67-a0d7-74d564884e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Open a file to write the output\n",
    "with open('output_results.txt', 'w') as f:\n",
    "    # Redirect stdout to the file\n",
    "    sys.stdout = f\n",
    "\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv('Merge_all_features_1639_with_class.csv')\n",
    "\n",
    "    # Split into features and target variable\n",
    "    X = df.drop(columns=df.columns[-1])\n",
    "    y = df[df.columns[-1]]\n",
    "\n",
    "    # Split data into training and testing sets (80:20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize RandomForestClassifier\n",
    "    clf_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Set up KFold cross-validation with 10 folds\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    cv_scores = []\n",
    "    cv_losses = []  # List to store losses for each fold\n",
    "    fold = 1\n",
    "\n",
    "    # Perform 10-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        # Start timing the model training\n",
    "        start_time = time.time()\n",
    "        \n",
    "        clf_rf.fit(X_fold_train, y_fold_train)\n",
    "        \n",
    "        # End timing the model training\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        \n",
    "        y_fold_pred = clf_rf.predict(X_fold_val)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_fold_pred)\n",
    "        \n",
    "        # Calculate the validation loss\n",
    "        y_fold_pred_proba = clf_rf.predict_proba(X_fold_val)\n",
    "        fold_loss = log_loss(y_fold_val, y_fold_pred_proba)\n",
    "        \n",
    "        cv_scores.append(fold_accuracy)\n",
    "        cv_losses.append(fold_loss)\n",
    "        \n",
    "        print(f\"Fold {fold} Validation Accuracy: {fold_accuracy*100:.2f}%, Validation Loss: {fold_loss:.4f}, Training Time: {training_time:.2f} seconds\")\n",
    "        fold += 1\n",
    "\n",
    "    # Calculate the mean cross-validation accuracy and loss\n",
    "    mean_cv_accuracy = sum(cv_scores) / len(cv_scores)\n",
    "    mean_cv_loss = sum(cv_losses) / len(cv_losses)\n",
    "    print(f\"\\nAverage Cross-Validation Accuracy: {mean_cv_accuracy*100:.2f}%\")\n",
    "    print(f\"Average Cross-Validation Loss: {mean_cv_loss:.4f}\")\n",
    "\n",
    "    # Start timing the final model training\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train the model on the entire training set\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "\n",
    "    # End timing the final model training\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_rf = clf_rf.predict(X_test)\n",
    "    y_pred_proba_rf = clf_rf.predict_proba(X_test)[:, 1]  # Get the probabilities for the positive class\n",
    "\n",
    "    # Calculate the test set accuracy\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "    print(f\"\\nTest Set Accuracy: {test_accuracy*100:.2f}% - Final Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "    # Generate and print the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Calculate and print additional metrics\n",
    "    precision = precision_score(y_test, y_pred_rf)\n",
    "    recall = recall_score(y_test, y_pred_rf)\n",
    "    f1 = f1_score(y_test, y_pred_rf)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred_rf)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba_rf)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "\n",
    "    # Calculate specificity\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    # Calculate false negative rate (FNR) and false positive rate (FPR)\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "    print(f\"\\nAccuracy: {test_accuracy*100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "    print(f\"False Negative Rate (FNR): {fnr:.4f}\")\n",
    "    print(f\"False Positive Rate (FPR): {fpr:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n",
    "    print(f\"AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "    # Reset stdout to default\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "# Notify that results have been saved\n",
    "print(\"Results have been saved to output_results.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b6cfb7-4179-41ff-9ca8-bbbc5d490b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af6eb0-068a-4f3a-b05a-9259427715be",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SVM ###########\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('48006x45_RF_MI.csv')\n",
    "\n",
    "# Split into features and target variable\n",
    "X = df.drop(columns=df.columns[-1])\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "# Scaling is important for SVM\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize an SVM Classifier with default parameters\n",
    "clf_svm = SVC()\n",
    "\n",
    "# 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "val_accuracies = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the classifier on the training fold\n",
    "    clf_svm.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_val_pred = clf_svm.predict(X_val_fold)\n",
    "    val_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "    \n",
    "    # Store the validation accuracy\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    # Print fold results\n",
    "    print(f\"Fold {len(val_accuracies)}:\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "    print()\n",
    "\n",
    "# Average validation accuracy\n",
    "avg_val_accuracy = np.mean(val_accuracies)\n",
    "print(f\"Average Validation Accuracy: {avg_val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Train the classifier on the entire training set\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = clf_svm.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "# Print test results\n",
    "print(f\"Test Set Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab0e67-d1bb-45d9-9022-31eee614c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## LR ###########\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('48006x45_RF_MI.csv')\n",
    "\n",
    "# Split into features and target variable\n",
    "X = df.drop(columns=df.columns[-1])\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "# Scaling can help Logistic Regression converge more efficiently\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a Logistic Regression Classifier\n",
    "clf_lr = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "# Set up 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Array to store validation accuracy scores\n",
    "val_accuracies = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_cv, X_val_cv = X_train[train_index], X_train[val_index]\n",
    "    y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the classifier\n",
    "    clf_lr.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_val_pred = clf_lr.predict(X_val_cv)\n",
    "    val_accuracy = accuracy_score(y_val_cv, y_val_pred)\n",
    "    \n",
    "    # Store validation accuracy\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    # Print validation accuracy for this fold\n",
    "    print(f\"Fold Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Calculate and print average validation accuracy\n",
    "avg_val_accuracy = np.mean(val_accuracies)\n",
    "print(f\"Average Validation Accuracy: {avg_val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Train the final model on the entire training set\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = clf_lr.predict(X_test)\n",
    "\n",
    "# Calculate the test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_lr)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f15a9-c0b0-4aba-90e5-9893b9883c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## KNN ###########\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('48006x45_RF_MI.csv')\n",
    "\n",
    "# Split into features and target variable\n",
    "X = df.drop(columns=df.columns[-1])\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "# Scaling is crucial for KNN as it's a distance-based algorithm\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Set up 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Array to store validation accuracy scores\n",
    "val_accuracies = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_cv, X_val_cv = X_train[train_index], X_train[val_index]\n",
    "    y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the classifier\n",
    "    knn.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_val_pred = knn.predict(X_val_cv)\n",
    "    val_accuracy = accuracy_score(y_val_cv, y_val_pred)\n",
    "    \n",
    "    # Store validation accuracy\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    # Print validation accuracy for this fold\n",
    "    print(f\"Fold Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Calculate and print average validation accuracy\n",
    "avg_val_accuracy = np.mean(val_accuracies)\n",
    "print(f\"Average Validation Accuracy: {avg_val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Train the final model on the entire training set\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Calculate the test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625cc086-b16c-41ca-b033-29e831d3495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## NB ###########\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('48006x45_RF_MI.csv')\n",
    "\n",
    "# Split into features and target variable\n",
    "X = df.drop(columns=df.columns[-1])\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Set up 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Array to store validation accuracy scores\n",
    "val_accuracies = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_cv, X_val_cv = X_train[train_index], X_train[val_index]\n",
    "    y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the classifier\n",
    "    nb.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_val_pred = nb.predict(X_val_cv)\n",
    "    val_accuracy = accuracy_score(y_val_cv, y_val_pred)\n",
    "    \n",
    "    # Store validation accuracy\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    # Print validation accuracy for this fold\n",
    "    print(f\"Fold Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Calculate and print average validation accuracy\n",
    "avg_val_accuracy = np.mean(val_accuracies)\n",
    "print(f\"Average Validation Accuracy: {avg_val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Train the final model on the entire training set\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "# Calculate the test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_nb)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08856a8c-86a2-4a20-8d0b-bb2caff3e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## DT ###########\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('48006x45_RF_MI.csv')\n",
    "\n",
    "# Split into features and target variable\n",
    "X = df.drop(columns=df.columns[-1])\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scaling is crucial for DT\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Set up 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Array to store validation accuracy scores\n",
    "val_accuracies = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_cv, X_val_cv = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the classifier\n",
    "    dt.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_val_pred = dt.predict(X_val_cv)\n",
    "    val_accuracy = accuracy_score(y_val_cv, y_val_pred)\n",
    "    \n",
    "    # Store validation accuracy\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    # Print validation accuracy for this fold\n",
    "    print(f\"Fold Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Calculate and print average validation accuracy\n",
    "avg_val_accuracy = np.mean(val_accuracies)\n",
    "print(f\"Average Validation Accuracy: {avg_val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Train the final model on the entire training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Calculate the test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680da0d-04e1-4e82-be33-ab8d87dab2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## GBDT ###########\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('48006x45_RF_MI.csv')\n",
    "\n",
    "# Split into features and target variable\n",
    "X = df.drop(columns=df.columns[-1])\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "# Scaling is crucial for GBDT\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Gradient Boosting classifier\n",
    "gbdt = GradientBoostingClassifier()\n",
    "\n",
    "# Set up 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Array to store validation accuracies\n",
    "val_accuracies = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_cv, X_val_cv = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the classifier\n",
    "    gbdt.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_val_pred = gbdt.predict(X_val_cv)\n",
    "    \n",
    "    # Calculate validation accuracy\n",
    "    val_accuracy = accuracy_score(y_val_cv, y_val_pred)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    # Print accuracy for this fold\n",
    "    print(f\"Fold Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Calculate and print average validation accuracy\n",
    "avg_val_accuracy = np.mean(val_accuracies)\n",
    "print(f\"Average Validation Accuracy: {avg_val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Train the final model on the entire training set\n",
    "gbdt.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_gbdt = gbdt.predict(X_test)\n",
    "\n",
    "# Calculate the test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_gbdt)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_gbdt)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4587151-6c0f-4297-bb50-4fcf08254547",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## LGBM ###########\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('48006x45_RF_MI.csv')\n",
    "\n",
    "# Split into features and target variable\n",
    "X = df.drop(columns=df.columns[-1])\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scaling is crucial for LGBM\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the LightGBM classifier\n",
    "lgbm = lgb.LGBMClassifier()\n",
    "\n",
    "# Set up 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Arrays to store validation accuracies\n",
    "val_accuracies = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_cv, X_val_cv = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the classifier\n",
    "    lgbm.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_val_pred = lgbm.predict(X_val_cv)\n",
    "    val_accuracy = accuracy_score(y_val_cv, y_val_pred)\n",
    "    \n",
    "    # Store validation accuracy\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    # Print validation accuracy for this fold\n",
    "    print(f\"Fold Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Calculate and print average validation accuracy\n",
    "avg_val_accuracy = np.mean(val_accuracies)\n",
    "print(f\"Average Cross-Validation Accuracy: {avg_val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Train the final model on the entire training set\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lgbm = lgbm.predict(X_test)\n",
    "\n",
    "# Calculate the test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_lgbm)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_lgbm)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd21686-d099-41aa-b666-16af31697cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## XGBoost ###########\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('48006x45_RF_MI.csv')\n",
    "\n",
    "# Split into features and target variable\n",
    "X = df.drop(columns=df.columns[-1])\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scaling is crucial for XGBoost\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb = XGBClassifier(use_label_encoder=False)  # Added parameter to suppress warnings\n",
    "\n",
    "# Set up KFold cross-validation (10 folds, not stratified)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# List to store validation accuracies for each fold\n",
    "validation_accuracies = []\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Train the model on the training fold\n",
    "    xgb.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_val_pred = xgb.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate validation accuracy\n",
    "    val_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "    validation_accuracies.append(val_accuracy)\n",
    "    print(f\"Fold Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Calculate and print the average cross-validation accuracy\n",
    "avg_val_accuracy = np.mean(validation_accuracies)\n",
    "print(f\"\\nAverage Cross-Validation Accuracy: {avg_val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Train the model on the entire training set\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Calculate the test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_xgb)\n",
    "print(f\"\\nConfusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af5c39-a160-4ac3-b7d5-b3881492bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## CatBoost ###########\n",
    "\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('48006x45_RF_MI.csv')\n",
    "\n",
    "# Split into features and target variable\n",
    "X = df.drop(columns=df.columns[-1])\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scaling is crucial for CatBoost\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize CatBoost classifier\n",
    "catboost = CatBoostClassifier(iterations=500, learning_rate=0.05, depth=7, verbose=0)\n",
    "\n",
    "# Set up 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Store validation accuracies\n",
    "validation_accuracies = []\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "    # Use .iloc[] for integer-based indexing\n",
    "    X_train_fold = X_train.iloc[train_index]\n",
    "    X_val_fold = X_train.iloc[val_index]\n",
    "    y_train_fold = y_train.iloc[train_index]\n",
    "    y_val_fold = y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the model on the current fold\n",
    "    catboost.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_val_pred = catboost.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate validation accuracy\n",
    "    val_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "    validation_accuracies.append(val_accuracy)\n",
    "    \n",
    "    print(f\"Fold {fold+1} Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Calculate and print the average cross-validation accuracy\n",
    "avg_cv_accuracy = np.mean(validation_accuracies)\n",
    "print(f\"\\nAverage Cross-Validation Accuracy: {avg_cv_accuracy*100:.2f}%\")\n",
    "\n",
    "# Train on the entire training set and evaluate on the test set\n",
    "catboost.fit(X_train, y_train)\n",
    "y_test_pred = catboost.predict(X_test)\n",
    "\n",
    "# Calculate the test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58912bfb-0882-420e-a585-1f90f7717949",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## AdaBoost ###########\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('48006x45_RF_MI.csv')\n",
    "\n",
    "# Split into features and target variable\n",
    "X = df.drop(columns=df.columns[-1])\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scaling is crucial for AdaBoost\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize AdaBoost classifier with a DecisionTree base estimator\n",
    "base_estimator = DecisionTreeClassifier(max_depth=7)  # Base estimator\n",
    "adaboost = AdaBoostClassifier(\n",
    "    n_estimators=50,\n",
    "    learning_rate=0.05,\n",
    "    algorithm='SAMME',  # Use the SAMME algorithm\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform 10-fold cross-validation on the training set\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(adaboost, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Print the validation accuracy for each fold\n",
    "for i, score in enumerate(cv_scores):\n",
    "    print(f\"Fold {i+1} Validation Accuracy: {score*100:.2f}%\")\n",
    "\n",
    "# Calculate the average cross-validation accuracy\n",
    "average_cv_accuracy = np.mean(cv_scores)\n",
    "print(f\"\\nAverage Cross-Validation Accuracy: {average_cv_accuracy*100:.2f}%\")\n",
    "\n",
    "# Train the classifier on the entire training set\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_ada = adaboost.predict(X_test)\n",
    "\n",
    "# Calculate the test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_ada)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_ada)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9160cd-625a-4e84-ab38-bae53dcfd0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## ANN ##########\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('48006x45_RF_MI.csv')\n",
    "\n",
    "# Split into features and target variable\n",
    "X = df.drop(columns=df.columns[-1])\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize KFold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_accuracies = []\n",
    "\n",
    "# Define a function to create the ANN model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Use 'softmax' for multi-class classification\n",
    "    model.compile(optimizer=Adam(), loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])\n",
    "    return model\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Create a new model instance for each fold\n",
    "    model = create_model()\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    cv_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Fold {fold+1} Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Print average cross-validation accuracy\n",
    "average_cv_accuracy = np.mean(cv_accuracies)\n",
    "print(f\"\\nAverage Cross-Validation Accuracy: {average_cv_accuracy*100:.2f}%\")\n",
    "\n",
    "# Train final model on the entire training set (80% of data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = create_model()\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Calculate the accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d2431c-3c3a-480e-85ec-de96c1e2cda2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6008f9da-a95e-4a30-a88e-cfc12c5d6499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
